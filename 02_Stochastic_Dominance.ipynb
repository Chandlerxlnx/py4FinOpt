{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Dominance\n",
    "\n",
    "To determine if one portfolio stochastically dominates another we first need to compute the CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defaultdict is a Python dictionary that \n",
    "# supports initial values for a key\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def compute_pdf(time_series):\n",
    "    d = sorted(time_series)\n",
    "    di = defaultdict(int)\n",
    "    inc = 1.0/len(d)\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        di[d[i]] += 1\n",
    "    \n",
    "    val  = []\n",
    "    prob = []\n",
    "    \n",
    "    for k in sorted(di.keys()):\n",
    "        val.append(k)\n",
    "        prob.append(inc*di[k])\n",
    "\n",
    "    return val, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And for the CDF\n",
    "def compute_cdf(prob):\n",
    "    cdf = [prob[0]]\n",
    "    for i in range(1, len(prob)):\n",
    "        cdf.append(prob[i] + cdf[i-1])\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2222222222222222, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111]\n",
      "[0.2222222222222222, 0.3333333333333333, 0.5555555555555556, 0.6666666666666667, 0.7777777777777779, 0.8888888888888891, 1.0000000000000002]\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 4, 6, 8, 9, 1, 4, 5]\n",
    "val, pdf = compute_pdf(data)\n",
    "cdf = compute_cdf(pdf)\n",
    "print pdf\n",
    "print cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to expand our current vectors over all the events\n",
    "def expand_vector(events, x, y):\n",
    "    index = 0\n",
    "    d_mod = []\n",
    "    for pnt in events:\n",
    "        if index >= len(x):\n",
    "            d_mod.append(y[-1])\n",
    "        elif pnt < x[index]:\n",
    "            if index == 0:\n",
    "                d_mod.append(0.0)\n",
    "            else:\n",
    "                d_mod.append(y[index-1])\n",
    "        elif pnt == x[index]:\n",
    "            d_mod.append(y[index])\n",
    "        else:\n",
    "            index += 1\n",
    "            if index >= len(x):\n",
    "                d_mod.append(y[-1])\n",
    "            elif x[index] == pnt:\n",
    "                d_mod.append(y[index])\n",
    "            else:\n",
    "                d_mod.append(y[index-1])\n",
    "    return d_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_fosd(d1, d2):\n",
    "    val1, pdf1 = compute_pdf(d1)\n",
    "    val2, pdf2 = compute_pdf(d2)\n",
    "    cdf1, cdf2 = map(compute_cdf, [pdf1, pdf2])\n",
    "    points = sorted(list(set(val1+val2)))\n",
    "    d1_mod = map(lambda x: round(x, 5), expand_vector(points, val1, cdf1))\n",
    "    d2_mod = map(lambda x: round(x, 5), expand_vector(points, val2, cdf2))\n",
    "    d1_fosd_d2 = all(map(lambda x, y: x<=y, d1_mod, d2_mod))\n",
    "    d2_fosd_d1 = all(map(lambda x, y: x>=y, d1_mod, d2_mod))\n",
    "    return d1_fosd_d2, d2_fosd_d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_sosd(d1, d2):\n",
    "    val1, pdf1 = compute_pdf(d1)\n",
    "    val2, pdf2 = compute_pdf(d2)\n",
    "    cdf1, cdf2 = map(compute_cdf, [pdf1, pdf2])\n",
    "    points = sorted(list(set(val1+val2)))\n",
    "    d1_mod = map(lambda x: round(x, 5), expand_vector(points, val1, cdf1))\n",
    "    d2_mod = map(lambda x: round(x, 5), expand_vector(points, val2, cdf2))\n",
    "    d1_areas = np.cumsum([d1_mod[i]*(points[i+1]-points[i]) for i in range(len(points)-1)])\n",
    "    d2_areas = np.cumsum([d2_mod[i]*(points[i+1]-points[i]) for i in range(len(points)-1)])\n",
    "    d1_sosd_d2 = all(map(lambda x, y: x<=y, d1_areas, d2_areas))\n",
    "    d2_sosd_d1 = all(map(lambda x, y: x>=y, d1_areas, d2_areas))\n",
    "    return d1_sosd_d2, d2_sosd_d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, False)\n",
      "(True, False)\n",
      "(False, False)\n",
      "(True, False)\n"
     ]
    }
   ],
   "source": [
    "d1 = [80, 80, 30, 30, 30, 60, 50, 50, 50, 50]\n",
    "d2 = [10, 10, 50, 50, 50, 70, 30, 30, 30, 30]\n",
    "d3 = [20, 80]\n",
    "d4 = [0, 100]\n",
    "# D1 FOSD D2\n",
    "print check_fosd(d1, d2)\n",
    "print check_sosd(d1, d2)\n",
    "print check_fosd(d3, d4)\n",
    "# D3 FOSD D4\n",
    "print check_sosd(d3, d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
